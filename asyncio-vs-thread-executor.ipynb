{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:13.425237Z",
     "start_time": "2024-12-18T02:13:13.420582Z"
    }
   },
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "1623de124a1fd644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:13.441364Z",
     "start_time": "2024-12-18T02:13:13.435493Z"
    }
   },
   "source": [
    "import asyncio\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "def _run_async(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        loop = asyncio.get_event_loop()\n",
    "        return loop.run_until_complete(f(*args, **kwargs))\n",
    "\n",
    "    return wrapper"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "afb210f437d67dfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:13.491825Z",
     "start_time": "2024-12-18T02:13:13.488443Z"
    }
   },
   "source": [
    "URLS = (\n",
    "    \"https://httpbin.org/delay/1\",\n",
    "    \"https://httpbin.org/delay/2\",\n",
    "    \"https://httpbin.org/delay/3\",\n",
    "    \"https://httpbin.org/status/400\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "d458720540c972ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:13.549981Z",
     "start_time": "2024-12-18T02:13:13.544048Z"
    }
   },
   "source": [
    "import requests\n",
    "import logging\n",
    "import tempfile\n",
    "import time\n",
    "import contextlib\n",
    "import uuid\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def temp_logger(file_name):\n",
    "    logger = logging.getLogger(str(uuid.uuid4()))\n",
    "    handler = logging.FileHandler(file_name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    try:\n",
    "        logger.addHandler(handler)\n",
    "        yield logger\n",
    "    finally:\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "\n",
    "def process_url_with_requests(url):\n",
    "    \"\"\"\n",
    "    1. Make a GET request.\n",
    "    2. If request fails, retry at most 5 times\n",
    "        and sleep for 0.5 seconds before each retry.\n",
    "    3. Log a response to a temporary file.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    with (\n",
    "        tempfile.NamedTemporaryFile(\"a+\") as file,\n",
    "        temp_logger(file.name) as logger,\n",
    "    ):\n",
    "        for _ in range(5):\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status()\n",
    "            except requests.exceptions.RequestException:\n",
    "                time.sleep(0.5)\n",
    "            else:\n",
    "                break\n",
    "        logger.info(f\"Response from URL %s is %s\", url, response.text)\n",
    "\n",
    "\n",
    "def process_urls_with_requests():\n",
    "    for url in URLS:\n",
    "        process_url_with_requests(url)"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "8597d43ea7f83950",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-18T02:13:13.591457Z"
    }
   },
   "source": "%timeit -r 1 -n 100 process_urls_with_requests()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7881216951925331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:08.519771141Z",
     "start_time": "2024-12-18T02:03:11.921070Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_url_with_requests_session(session: requests.Session, url):\n",
    "    \"\"\"\n",
    "    1. Make a GET request.\n",
    "    2. If request fails, retry at most 5 times\n",
    "        and sleep for 0.5 seconds before each retry.\n",
    "    3. Log a response to a temporary file.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    with (\n",
    "        tempfile.NamedTemporaryFile(\"a+\") as file,\n",
    "        temp_logger(file.name) as logger,\n",
    "    ):\n",
    "        for _ in range(5):\n",
    "            try:\n",
    "                response = session.get(url)\n",
    "                response.raise_for_status()\n",
    "            except requests.exceptions.RequestException:\n",
    "                time.sleep(0.5)\n",
    "            else:\n",
    "                break\n",
    "        logger.info(f\"Response from URL %s is %s\", url, response.text)\n",
    "\n",
    "\n",
    "def process_urls_with_requests_session():\n",
    "    with requests.Session() as session:\n",
    "        for url in URLS:\n",
    "            process_url_with_requests_session(session, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35076431d545f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:08.520923010Z",
     "start_time": "2024-12-18T01:08:06.729870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 s ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 1 -n 100 process_urls_with_requests_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c9abc777d98ba54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:08.536244011Z",
     "start_time": "2024-12-18T02:03:14.195234Z"
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def process_urls_with_requests_session_and_threads():\n",
    "    with (\n",
    "        requests.Session() as session,\n",
    "        ThreadPoolExecutor(max_workers=len(URLS)) as executor,\n",
    "    ):\n",
    "        for url in URLS:\n",
    "            executor.submit(process_url_with_requests_session, session, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82970539631e32e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:08.536929963Z",
     "start_time": "2024-12-18T01:09:56.514962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44 s ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 1 -n 100 process_urls_with_requests_session_and_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6211f44ecc74a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:08.541587204Z",
     "start_time": "2024-12-18T02:03:16.374860Z"
    }
   },
   "outputs": [],
   "source": [
    "async def process_urls_with_requests_session_and_threads_async_wraps_future_structured():\n",
    "    \"\"\"This coroutine would finish only when all the urls were processed.\"\"\"\n",
    "    with (\n",
    "        requests.Session() as session,\n",
    "        ThreadPoolExecutor(max_workers=len(URLS)) as executor,\n",
    "    ):\n",
    "        futures = [\n",
    "            asyncio.wrap_future(\n",
    "                executor.submit(process_url_with_requests_session, session, url)\n",
    "            )\n",
    "            for url in URLS\n",
    "        ]\n",
    "        await asyncio.gather(*futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "230bdc419072af2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:08.543061354Z",
     "start_time": "2024-12-18T01:10:41.067841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41 s ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 1 -n 100 _run_async(process_urls_with_requests_session_and_threads_async_wraps_future_structured)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70e93bd503018c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:08.551355276Z",
     "start_time": "2024-12-18T02:09:51.916626Z"
    }
   },
   "outputs": [],
   "source": [
    "from loguru import logger as loguru_logger\n",
    "import httpx\n",
    "import aiofiles\n",
    "import stamina\n",
    "\n",
    "stamina.instrumentation.set_on_retry_hooks([])\n",
    "loguru_logger.remove()\n",
    "\n",
    "\n",
    "@contextlib.asynccontextmanager\n",
    "async def temp_logger_async(file_name):\n",
    "    logger = loguru_logger.bind(task=(task := str(uuid.uuid4())))\n",
    "    handler_id = logger.add(\n",
    "        file_name, filter=lambda record: record[\"extra\"][\"task\"] == task, enqueue=True\n",
    "    )\n",
    "    try:\n",
    "        yield logger\n",
    "    finally:\n",
    "        logger.remove(handler_id)\n",
    "\n",
    "\n",
    "async def process_url_async(client: httpx.AsyncClient, url):\n",
    "    \"\"\"\n",
    "    1. Make a GET request.\n",
    "    2. If request fails, retry at most 5 times\n",
    "        and sleep for 0.5 seconds before each retry.\n",
    "    3. Log a response to a temporary file.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    async with (\n",
    "        aiofiles.tempfile.NamedTemporaryFile(\n",
    "            \"a+\", delete=False, delete_on_close=False\n",
    "        ) as file,\n",
    "        temp_logger_async(file.name) as logger,\n",
    "    ):\n",
    "        with contextlib.suppress(httpx.HTTPError):\n",
    "            async for attempt in stamina.retry_context(\n",
    "                on=httpx.HTTPError, attempts=5, wait_max=0.5\n",
    "            ):\n",
    "                with attempt:\n",
    "                    response = await client.get(url)\n",
    "                    response.raise_for_status()\n",
    "        logger.info(\"Response from URL {url} is {text}\", url=url, text=response.text)\n",
    "\n",
    "\n",
    "async def process_urls_async():\n",
    "    async with httpx.AsyncClient() as client, asyncio.TaskGroup() as tg:\n",
    "        for url in URLS:\n",
    "            tg.create_task(process_url_async(client, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbdeb1b822f067a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:13:08.554363371Z",
     "start_time": "2024-12-18T02:09:52.387726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 1 -n 100 _run_async(process_urls_async)()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
